## **VGGT: Visual Geometry Grounded Transformer (CVPR 2025)**

**VGGT란?**

- 한 장 또는 여러 장의 이미지를 입력받아 카메라 파라미터, 포인트 맵, 깊이 맵, 3D 포인트 트랙 등 장면의 주요 3D 속성을 한 번의 feed-forward 연산으로 추론하는 신경망
- 후처리 없이 3D scene reconstruction을 1초 이내로 수행
- gpt처럼 특정 작업에 국한되지 않고 다양한 3D 작업에 재활용 가능한 범용 트랜스포머 기반 모델

<aside>
💡

3D scene reconstruction이란?

2D 이미지 속 장면을 컴퓨터가 이해할 수 있는 입체적인 3D 형태로 변환하는 기술

VGGT는 사진 몇 장만 보고 그 공간의 깊이, 카메라 위치, 물체의 3차원 구조를 자동으로 추정하는 2D to 3D reconstruction 모델

</aside>

**Problem setting & introduction**

지금까지 3D reconstruction 모델들은 사진 여러 장을 가지고 카메라 위치와 물체의 모양을 **반복적으로 계산해** 맞춰야 했다

이 과정은 느리고 복잡할 뿐 아니라, 두 장면씩 따로 계산한 뒤 결과를 합치는 후처리도 필요했다

VGGT는 이런 복잡한 과정을 없애고, **한 번의 신경망 연산만으로** 카메라 위치·깊이·3D 구조를 빠르게 예측할 수 있도록 만들어졌다.

또한, **현존하는 3D reconstruction 모델 중 최고 수준(SOTA) 성능**을 달성했다.

**한계점**

- VGGT는 정적 장면에서 우수한 성능을 보이지만, 물체의 비선형적 변형(구부러짐, 늘어남, 왜곡 등)이 발생하는 동적 장면에서는 정확도가 떨어질 수 있다
- 트랜스포머 기반 대규모 모델이기 때문에 입력 이미지가 많거나 고해상도일 경우 GPU 메모리와 연산 비용이 크게 증가한다

